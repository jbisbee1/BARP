\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={BARP: MRP - Multilevel + BART},
            pdfauthor={James Bisbee (NYU)},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\providecommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

  \title{BARP: MRP - Multilevel + BART}
    \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
    \author{James Bisbee (NYU)}
    \preauthor{\centering\large\emph}
  \postauthor{\par}
      \predate{\centering\large\emph}
  \postdate{\par}
    \date{\href{mailto:james.bisbee@nyu.edu}{\nolinkurl{james.bisbee@nyu.edu}}}


\begin{document}
\maketitle

Multilevel Regression and Poststratification (MRP or, colloqially,
Mister P) is the current gold standard for extrapolating opinions to
smaller units of interest than the survey was originally designed to
represent. MRP's performance is well-documented in papers by Lax and
Phillips (2009), Warshaw and Rodden (2012), and Buttice and Highton
(2013), who successfully recover state- and district-level estimates of
opinion from nationally representative surveys.

However, advances in machine learning can improve on MRP by replacing
the multilevel model with more sophosticated prediction algorithms. BARP
is one such example that uses Bayesian Additive Regression Trees
(Chipman, George, and McCulloch 2010) in lieu of the multilevel model.
In a test of predictive accuracy across 89 surveys (Bisbee 2019), BARP
yields consistently superior accuracy as measured by both Mean Absolute
Error (MAE) and interstate correlation.

In this vignette, I walk through an applied example using the
\textbf{BARP} package for \textbf{R}. I use the data included with the
\textbf{BARP} package which consists of:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  A nationally representative survey of support for gay marriage fielded
  in 2006.
\item
  Census data giving the share of the population falling into different
  covariate bins (i.e.~the share that is a black female with a college
  degree between the ages of 31 and 50) for the geographic unit of
  interest (in this example, US states).
\end{enumerate}

This vignette is designed to demonstrate the functions associated with
the \textbf{BARP} package. Readers interested in the details of the
method are encouraged to refer to Bisbee (2019).

The vignette proceeds as follows: \textbf{Section 0} presents a brief
overview of Bayesian Additive Regression Trees. Interested readers are
encouraged to refer to Chipman, George, and McCulloch (2010).

In \textbf{Section 1} I demonstrate how to implement the basic
\texttt{barp} function to generate state-level opinions from nationally
representative data. I show how to estimate upper and lower bounds of
these values through either Bayesian credible intervals or through
bootstrapping over random samples of the data.

In \textbf{Section 2} I demonstrate how to explore the partial
depedencies generated by the model using the
\texttt{barp\_partial\_dependence} function. This function allows the
researcher to evaluate which covariates are most strongly associated
with support of, or opposition to, a given topic. The function allows
for up to three-way interaction estimation, permitting rich
characterizations of how the supplied covariates predict the opinion of
interest.

\textbf{Section 3} evaluates the prognostic power of the covariates by
examining the number of times they are used as a ``splitting rule'' (see
section 3.1 for more details). The number of times the covariates are
used is known as the ``variable inclusion proportion''. Following Bleich
et al. (2014), I permute the outcome variable to break any connection
with the covariates and re-estimate the variable inclusion proportions
to generate a null distribution. Against that null distribution I
evaluate the significance of variable inclusion. I also discuss methods
for dealing with missing data, introduced in Kapelner and Bleich (2015).

\textbf{Section 4} describes how to implement alternative prediction
algorithms. Users can instantiate any one of the 43 different algorithms
included in the \texttt{SuperLearner} package (Polley and Van der Laan
2015), the full list of which is viewable with a call to the
\texttt{listWrappers()} function. These functions can be run in
isolation or in combination, in which case the package will return both
the predictions associated with each algorithm as well as those
predictions generated by a weighted ensemble of all algorithms, with
weights calculated with 10-fold cross validation.

\textbf{Section 5} concludes.

\subsection{0.0 A BART primer}\label{a-bart-primer}

This section introduces Bayesian Additive Regression Trees. Users are
encouraged to refer to Chipman, George, and McCulloch (2010) for a more
detailed discussion.

A single regression tree \(\mathcal{T}\) approximates an unknown
function \(f\) by recursively partitioning the covariate space
(\(\mathbf{X}\)) to best organize observations (\(i\)) according to some
outcome \(Y\). The resulting bins (commonly referred to as ``nodes'' or
``leafs'') proceed until a stopping criteria is met. Each terminal node
\(b\) is associated with a parameter value \(\mu_b\) which combine to
form the set \(\mathcal{M}\). Observed values of \(x \in \mathcal{X}\)
are assigned to a \(\mu_i \in \mathcal{M}\) by a function
\(g(x; \mathcal{T},\mathcal{M})\) which is an approximation of the
unknown function \(f\). Armed with many such trees indexed by \(t\), the
researcher can predict \(Y\) via

\[ Y = \sum_{t=1}^T g(\mathbf{X}; \mathcal{T}_t,\mathcal{M}_t) + \epsilon, \hspace{1cm} \epsilon \sim \mathcal{N}(0,\sigma^2)\]
The Bayesian aspect of BART imposes priors on the parameters
\((\mathcal{T}_t,\mathcal{M}_t)\) and \(\sigma^2\), the details of which
can be found in Chipman, George, and McCulloch (2010).

Consider a simplified example where \(y_i\) is an individual's (\(i\))
opinion on gay marriage and \(\mathbf{X}\) includes information on
respondent age, educational attainment, and state of residence. A
regression tree might first divide the data into one group (known as a
``node'' or a ``leaf'') over 35 years of age, and the other group
younger if this division most cleanly separates supports of gay marriage
from opponents. The algorithm might then divide the data based on
gender, then back again on age, then on state of residence, each time
further separating sub-groups of respondents into supporters and
opponents. Each division is called a ``splitting rule'' where the
``splitting variable'' \(x_j\) is divided at a ``splitting value''
\(c\).

When the tree stops growing (based on a pre-specified depth or a minimum
limit on the number of observations in each terminal node), the terminal
nodes each contain a fraction of the original observations characterized
by observed opinions and a particular sequence of splitting rules. So
for example, a terminal node containing 10 survey respondents, 9 of whom
oppose gay marriage, may have been created by selecting those over 35,
those without a college degree, those living in the Northeast, those
\emph{under} 50, and those living in Massachusetts. This particular
sequence of splitting rules is then assigned a parameter \(\mu\)
capturing the aggregate opposition to gay marriage in this group. Armed
with these terminal nodes and set of parameters
\(\mu_i \in \mathcal{M}\), the researcher can then predict opinions
using new data or use the estimated functions \(g\) to evaluate the
partial dependence between a given covariate and the outcome.

Repeating this process many times using the regularization priors on
\((\mathcal{T}_t,\mathcal{M}_t)\) and \(\sigma^2\) yields a rich
characterization of the unobservable function \(f\). Draws from the
posterior distribution of \(Pr(\mathcal{T}_t,\mathcal{M}_t,\sigma^2|Y)\)
leverage a Metropolis-within-Gibbs sampler which first proposes a change
to the structure of \(\mathcal{T_1}\), either by growing a terminal
node, pruning two child nodes, or changing one of the splitting rules.
Samples of \(\mathcal{M}_1\) are then drawn from this new structure and
this process repeats for each tree in \(\mathcal{T}\). Finally, a new
draw of \(\sigma^2\) completes the sampler, providing an estimate of
\(f\).

The discussion above deals with continuous outcome variables. In
applications to binary opinion data, BART can be fruitfully implemented
as a linear probability method. However, if \(Y\) is coded as a factor,
BART can instead be used for classification with a probit model
\(Pr(Y = 1|\mathbf{X} = \Phi(\sum_{t = 1}^Tg(\mathbf{X};\mathcal{T}_t,\mathcal{M}_t))\).
(Naturally, no prior is needed for \(\sigma_2\) since the probit assumes
\(\sigma^2 = 1\).) The latent variable \(Z\) is added to the sampler,
replacing \(Y\) after the additional step:

\[Z_i|y_i = 1 \sim max\bigg\{\mathcal{N}\bigg(\sum_{t = 1}^Tg(\mathbf{X};\mathcal{T}_t,\mathcal{M}_t)\bigg),0\bigg\} \\
Z_i|y_i = 0 \sim min\bigg\{\mathcal{N}\bigg(\sum_{t = 1}^Tg(\mathbf{X};\mathcal{T}_t,\mathcal{M}_t)\bigg),0\bigg\}\]

From this brief introduction, it should be clear that BART possesses two
attractive qualities. First, it allows for deep interactions that grow
exponentially in the number of covariates as well as the allowed tree
depth. Second, the ensemble character of the method can capture additive
effects. These qualities allow for superior estimation of the unknown
function \(f\) relative to multilevel models and relax the requirement
that the research define the functional form correctly \emph{a priori}.
In the context of extrapolating public opinion through
post-stratification, BART's superior predictive performance is
particularly attractive, as discussed in detail in Bisbee (2019). In the
ensuing sections, I demonstrate how to easily leverage BART's predictive
power with the \textbf{BARP} package for \textbf{R}.

\subsection{\texorpdfstring{1.0 Predicting opinions with
\texttt{barp}}{1.0 Predicting opinions with barp}}\label{predicting-opinions-with-barp}

\texttt{barp} is the main function in the \textbf{BARP} package and
produces objects of class \texttt{barp} which then can be used in other
functions. A \texttt{barp} object is a list containing two components.
The first is a \texttt{data.frame} that gives the predicted opinion, and
the lower and upper bounds for each geographic unit of interest. The
second is the \texttt{bartMachine} object (Kapelner and Bleich 2013). I
demonstrate the function below.

While the package was originally built with the intention of
implementing Bayesian Additive Regression Trees, it has since been
expanded to accommodate a number of alternative regularization
algorithms via the \texttt{SuperLearner} package. These alternative
algorithms will return predicted opinions in the same
\texttt{data.frame} object but users will not be able to examine partial
dependencies or prognostic covariate strength. I return to a brief
discussion of how to run \textbf{BARP} with alternative regularization
algorithms at the end of this vignette.

\subsubsection{\texorpdfstring{1.1 Installing \textbf{BARP} and setting
available
memory}{1.1 Installing BARP and setting available memory}}\label{installing-barp-and-setting-available-memory}

\textbf{BARP} implements Bayesian Additive Regression Trees using the
\textbf{bartMachine} package developed by Adam Kapelner and Justin
Bleich (Kapelner and Bleich 2013). This requires \texttt{rJava};
installing \texttt{rJava} on a Windows PC can be tricky because some
machines require users to manually set the \texttt{PATH} to their Java
bin. For users confronting errors, a good start can be found
\href{https://www.r-statistics.com/2012/08/how-to-load-the-rjava-package-after-the-error-java_home-cannot-be-determined-from-the-registry/}{here}.
(But Googling the specific error is always the best method.)

Once \texttt{rJava} is installed, \textbf{BARP} can be installed as
follows:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{require}\NormalTok{(devtools)}
\KeywordTok{install_github}\NormalTok{(}\StringTok{'jbisbee1/BARP'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

With \textbf{BARP} installed, the first thing to do \emph{before}
loading the package is set the memory available to Java with
\texttt{options(java.parameters\ =\ "-Xmx{[}NUM{]}g")} where
\texttt{{[}NUM{]}} refers to the number of gigabytes of memory to use.
For common opinion datasets (i.e. \textless{} 5,000 rows and \textless{}
20 covariates), 3 GB should suffice.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{options}\NormalTok{(}\DataTypeTok{java.parameters =} \StringTok{"-Xmx5g"}\NormalTok{)}
\KeywordTok{require}\NormalTok{(BARP)}
\end{Highlighting}
\end{Shaded}

\subsubsection{1.2 Loading the data and predicting
opinions}\label{loading-the-data-and-predicting-opinions}

We can now proceed to extrapolating opinions on gay marriage to the
state level. Following Buttice and Highton (2013), I will use four
individual-level covariates (age, education, and the interaction of
gender and race), two state-level covariates (Republican presidential
vote-share in the preceding election, and the share of the population
identifying as a ``religious conservative''), and two geographic
indicators (state, and region). \emph{Note} that the geographic unit of
interest to the user (\texttt{geo.unit}) \textbf{must} be included in
the vector of covariates. The outcome opinion in this example is
opposition to gay marriage, surveyed in 2006.

The main parameters used by the \texttt{barp} function include:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  the survey data \texttt{dat}
\item
  the census data \texttt{census}
\item
  variable names for the outcome \texttt{y} and covariates \texttt{x}
\item
  variable name of the geographic unit of interest \texttt{geo.unit}
\end{enumerate}

The user should also specify the name of the column in the census data
that lists the proportions or shares that fall into each covariate
category (\texttt{proportion}). If left to the default ``None'',
\texttt{barp} assumes that the census data is raw and calculates the
proportions by counting the number of rows for each covariate bin over
the total rows per geographic unit.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{data}\NormalTok{(}\StringTok{"gaymar"}\NormalTok{)}
\NormalTok{census06 <-}\StringTok{ }\NormalTok{census06 }\OperatorTok{%>%}\StringTok{ }\KeywordTok{merge}\NormalTok{(svy }\OperatorTok{%>%}\StringTok{ }\NormalTok{dplyr}\OperatorTok{::}\KeywordTok{select}\NormalTok{(state,stateid) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{distinct}\NormalTok{())}
\NormalTok{factors <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"region"}\NormalTok{,}\StringTok{"gXr"}\NormalTok{,}\StringTok{"state"}\NormalTok{)}
\NormalTok{census06[factors] <-}\StringTok{ }\KeywordTok{lapply}\NormalTok{(census06[factors],factor)}
\NormalTok{svy[}\KeywordTok{c}\NormalTok{(factors)] <-}\StringTok{ }\KeywordTok{lapply}\NormalTok{(svy[}\KeywordTok{c}\NormalTok{(factors)],factor)}
\NormalTok{barp.obj <-}\StringTok{ }\KeywordTok{barp}\NormalTok{(}\DataTypeTok{y =} \StringTok{"supp_gaymar"}\NormalTok{,}
                 \DataTypeTok{x =} \KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{,}\StringTok{"educ"}\NormalTok{,}\StringTok{"gXr"}\NormalTok{,}
                       \StringTok{"pvote"}\NormalTok{,}\StringTok{"religcon"}\NormalTok{,}
                       \StringTok{"state"}\NormalTok{,}\StringTok{"region"}\NormalTok{),}
                 \DataTypeTok{dat =}\NormalTok{ svy,}\DataTypeTok{census =}\NormalTok{ census06,}
                 \DataTypeTok{geo.unit =} \StringTok{"state"}\NormalTok{,}
                 \DataTypeTok{proportion =} \StringTok{"n"}\NormalTok{,}
                 \DataTypeTok{seed =} \DecValTok{1021}\NormalTok{,}
                 \DataTypeTok{serialize =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The resulting \texttt{barp} object summarizes the predicted opinions and
bounds as a \texttt{data.frame}. Plotting the \texttt{barp} object will
return either a simple plot of the predicted values and credible
intervals (\texttt{evaluate\_model\ =\ FALSE}, the default), or a set of
convergence diagnostic plots (\texttt{evaluate\_model\ =\ TRUE}). The
latter plot should exhibit relative stability across the post-burn-in
Markov Chain Monte Carlo (MCMC) simulations in terms of percent
acceptance, number of leafs and terminal nodes, and tree depth (and
\(\sigma^2\) when \(y\) is not a factor).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{barp.obj}\OperatorTok{$}\NormalTok{pred.opn }\OperatorTok{%>%}\StringTok{ }\KeywordTok{head}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   state SL.bartMachine_1_All     opn.lb    opn.ub
## 1    AL            0.1422521 0.04367446 0.2383575
## 2    AR            0.1268787 0.02760524 0.2212013
## 3    AZ            0.3222951 0.22747162 0.4159995
## 4    CA            0.3714351 0.28748739 0.4525278
## 5    CO            0.3655661 0.27821291 0.4564940
## 6    CT            0.4506066 0.36040250 0.5372730
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(barp.obj,}\DataTypeTok{algorithm =} \StringTok{"BARP"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{BARP_files/figure-latex/VigFig1-barpplot-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(barp.obj,}\DataTypeTok{evaluate_model =}\NormalTok{ T)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{BARP_files/figure-latex/VigFig2-barpploteval-1} \end{center}

Alternatively, the user can choose to calculate the upper and lower
bounds using bootstrapped simulations by setting \texttt{BSSD\ =\ TRUE}
and defining the number of simulations through the \texttt{nsims}
parameter. (Note that doing so will multiply the compute time
accordingly). The user can set the credible intervals for the bounds
with \texttt{cred\_int\ =\ c(0.025,0.975)}. Lastly, additional arguments
can be passed to \textbf{bartMachine} including \texttt{num\_trees},
\texttt{num\_burn\_in}, \texttt{num\_iterations\_after\_burn\_in},
\texttt{verbose}, et cetera. These parameters are non-trivial and should
be adjusted based on evaluating model performance via
\texttt{evaluate\_model\ =\ TRUE} in the \texttt{plot} function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{barp.obj2 <-}\StringTok{ }\KeywordTok{barp}\NormalTok{(}\DataTypeTok{y =} \StringTok{"supp_gaymar"}\NormalTok{,}
                  \DataTypeTok{x =} \KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{,}\StringTok{"educ"}\NormalTok{,}\StringTok{"gXr"}\NormalTok{,}
                       \StringTok{"pvote"}\NormalTok{,}\StringTok{"religcon"}\NormalTok{,}
                       \StringTok{"state"}\NormalTok{,}\StringTok{"region"}\NormalTok{),}
                  \DataTypeTok{dat =}\NormalTok{ svy,}\DataTypeTok{census =}\NormalTok{ census06,}
                  \DataTypeTok{geo.unit =} \StringTok{"state"}\NormalTok{,}
                  \DataTypeTok{proportion =} \StringTok{"n"}\NormalTok{,}
                  \DataTypeTok{BSSD =}\NormalTok{ T,}
                  \DataTypeTok{nsims =} \DecValTok{50}\NormalTok{,}
                  \DataTypeTok{num_trees =} \DecValTok{40}\NormalTok{,}
                  \DataTypeTok{num_burn_in =} \DecValTok{250}\NormalTok{,}
                  \DataTypeTok{num_iterations_after_burn_in =} \DecValTok{250}\NormalTok{,}
                  \DataTypeTok{setSeed =} \DecValTok{1021}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(barp.obj2)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{BARP_files/figure-latex/VigFig3-barpBSplot-1} \end{center}

\subsubsection{1.2.1 Classification vs
regression}\label{classification-vs-regression}

As mentioned in \textbf{Section 0.0}, \texttt{bartMachine} can handle
classification tasks in addition to conventional prediction. The user
can prompt \texttt{bartMachine} to execute its classification algorithm
by making \(y\) a factor. However, care must be taken when ordering the
factor as the predicted probabilities are based on the first value.
Failing to account for this (somewhat unintuitive) nuance will result in
predicted probabilities that are inverted.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{svy}\OperatorTok{$}\NormalTok{supp_gaymar <-}\StringTok{ }\KeywordTok{factor}\NormalTok{(svy}\OperatorTok{$}\NormalTok{supp_gaymar,}\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\StringTok{"1"}\NormalTok{,}\StringTok{"0"}\NormalTok{))}
\NormalTok{barp.class <-}\StringTok{ }\KeywordTok{barp}\NormalTok{(}\DataTypeTok{y =} \StringTok{"supp_gaymar"}\NormalTok{,}
                 \DataTypeTok{x =} \KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{,}\StringTok{"educ"}\NormalTok{,}\StringTok{"gXr"}\NormalTok{,}
                       \StringTok{"pvote"}\NormalTok{,}\StringTok{"religcon"}\NormalTok{,}
                       \StringTok{"state"}\NormalTok{,}\StringTok{"region"}\NormalTok{),}
                 \DataTypeTok{dat =}\NormalTok{ svy,}\DataTypeTok{census =}\NormalTok{ census06,}
                 \DataTypeTok{geo.unit =} \StringTok{"state"}\NormalTok{,}
                 \DataTypeTok{proportion =} \StringTok{"n"}\NormalTok{,}
                 \DataTypeTok{setSeed =} \DecValTok{1021}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(barp.class)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{BARP_files/figure-latex/VigFig4-barpclassplot-1} \end{center}

While in most cases the difference between the default and
classification routines is trivial, users can examine the confusion
matrix of the classification object to gain further insight on model
performance and tweak the \texttt{prob\_rule\_class} parameter to
improve the predictive power. (Note for applications of BARP to extract
representative estimates of opinion at different geographic units, these
changes barely influence unit-level predictions.)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{barp.class}\OperatorTok{$}\NormalTok{trees}\OperatorTok{$}\NormalTok{confusion_matrix}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##            predicted 1 predicted 0 model errors
## actual 1       245.000    1260.000        0.837
## actual 0       156.000    3339.000        0.045
## use errors       0.389       0.274        0.283
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{barp.class2 <-}\StringTok{ }\KeywordTok{barp}\NormalTok{(}\DataTypeTok{y =} \StringTok{"supp_gaymar"}\NormalTok{,}
                 \DataTypeTok{x =} \KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{,}\StringTok{"educ"}\NormalTok{,}\StringTok{"gXr"}\NormalTok{,}
                       \StringTok{"pvote"}\NormalTok{,}\StringTok{"religcon"}\NormalTok{,}
                       \StringTok{"state"}\NormalTok{,}\StringTok{"region"}\NormalTok{),}
                 \DataTypeTok{dat =}\NormalTok{ svy,}\DataTypeTok{census =}\NormalTok{ census06,}
                 \DataTypeTok{geo.unit =} \StringTok{"state"}\NormalTok{,}
                 \DataTypeTok{proportion =} \StringTok{"n"}\NormalTok{,}\DataTypeTok{prob_rule_class =} \FloatTok{0.45}\NormalTok{,}\DataTypeTok{setSeed =} \DecValTok{1021}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{barp.class2}\OperatorTok{$}\NormalTok{trees}\OperatorTok{$}\NormalTok{confusion_matrix}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##            predicted 1 predicted 0 model errors
## actual 1       418.000    1087.000        0.722
## actual 0       330.000    3165.000        0.094
## use errors       0.441       0.256        0.283
\end{verbatim}

\subsection{\texorpdfstring{2.0 Partial dependencies with
\texttt{barp}}{2.0 Partial dependencies with barp}}\label{partial-dependencies-with-barp}

The user may also be interested in the substantive relationships between
covariates and the outcome. The \textbf{BARP} package includes tools to
facilitate this type of analysis.

\subsubsection{2.1 Calculating partial
dependencies}\label{calculating-partial-dependencies}

The \texttt{barp\_partial\_dependence} function estimates partial
dependence for deep interactions between the covariates using the
\texttt{barp} object. The predicted values of the outcome are estimated
at different values of the covariate(s) of interest and can be analyzed
to make inferential statements about the relationship between the
covariates and the outcome, analogous to the coefficients and standard
errors of conventional regression analysis.

The \texttt{vars} parameter allows the user to indicate which covariates
to explore and, if desired, define the values at which the partial
dependence should be estimated. If only the variable names are entered
as a character vector, the levels are automatically generated by
splitting the support of the variable into quantiles at
\texttt{c(0.05,seq(.1,.9,by\ =\ .1),.95)} and taking the unique values.
Otherwise, the \texttt{vars} parameter must be named list where the
names are the variables of interest and the contents are the custom
values.

The user can also choose how much of the original data to use when
calculating the partial dependence through the \texttt{prop\_data}
parameter, allowing for faster calculation times at the cost of less
precise estimates. The value should be a numeric value between 0 and 1,
corresponding to the share of the total data. Lastly, the user can
stipulate the credible interval bounds through the
\texttt{credible\_interval} parameter.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bpd <-}\StringTok{ }\KeywordTok{barp_partial_dependence}\NormalTok{(}\DataTypeTok{barp =}\NormalTok{ barp.obj,}
                               \DataTypeTok{vars =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{age =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{4}\NormalTok{),}\DataTypeTok{educ =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{4}\NormalTok{)),}
                               \DataTypeTok{prop_data =}\NormalTok{ .}\DecValTok{2}\NormalTok{,}
                               \DataTypeTok{credible_interval =} \KeywordTok{c}\NormalTok{(}\FloatTok{0.025}\NormalTok{,}\FloatTok{0.975}\NormalTok{),}
                               \DataTypeTok{setSeed =} \DecValTok{1021}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The resulting object of class \texttt{bpd} contains a list of two
components. The first component is a summary \texttt{data.frame}, which
gives the predicted outcome and the lower and upper bounds for each
value of each variable. The second component is a raw
\texttt{data.frame} that gives the posterior predictions (rows) for each
value of each variable (columns). The user can make inferential
statements using either component of the \texttt{bpd} object or can rely
on default plotting methods, described below in Section 3.2.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{round}\NormalTok{(bpd}\OperatorTok{$}\NormalTok{summary }\OperatorTok{%>%}\StringTok{ }\KeywordTok{head}\NormalTok{(),}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   age educ  pred    lb    ub
## 1   1    1 0.483 0.409 0.559
## 2   2    1 0.342 0.285 0.405
## 3   3    1 0.251 0.203 0.300
## 4   4    1 0.126 0.076 0.175
## 5   1    2 0.476 0.421 0.540
## 6   2    2 0.342 0.304 0.385
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{round}\NormalTok{(bpd}\OperatorTok{$}\NormalTok{raw[,}\DecValTok{1}\OperatorTok{:}\DecValTok{4}\NormalTok{] }\OperatorTok{%>%}\StringTok{ }\KeywordTok{head}\NormalTok{(),}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   age1_educ1 age2_educ1 age3_educ1 age4_educ1
## 1      0.487      0.368      0.264      0.141
## 2      0.503      0.358      0.275      0.158
## 3      0.454      0.317      0.243      0.113
## 4      0.497      0.373      0.282      0.092
## 5      0.451      0.368      0.307      0.148
## 6      0.478      0.327      0.263      0.135
\end{verbatim}

\subsubsection{2.2 Plotting partial
dependence}\label{plotting-partial-dependence}

\textbf{BARP} provides a default plotting function to streamline the
visualization of the partial dependence results up to three-way
interactions. This function allows the user to provide variable names
(through the \texttt{var\_names} parameter) and level descriptions
(through the \texttt{var\_labs} parameter), as well as an indicator for
which variables are categorical and which are not
(\texttt{is\_categorical}). The type of plot produced will depend on how
many variables are included as well as whether or not each is
categorical.

For a single variable, the plot type is a function of whether the
variable is categorical or continuous, as illustrated.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bpd1 <-}\StringTok{ }\KeywordTok{barp_partial_dependence}\NormalTok{(}\DataTypeTok{barp =}\NormalTok{ barp.obj,}
                               \DataTypeTok{vars =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{age =} \DecValTok{1}\OperatorTok{:}\DecValTok{4}\NormalTok{),}
                               \DataTypeTok{prop_data =}\NormalTok{ .}\DecValTok{2}\NormalTok{,}
                               \DataTypeTok{setSeed =} \DecValTok{1021}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p1 <-}\StringTok{ }\KeywordTok{plot}\NormalTok{(bpd1,}\DataTypeTok{var_names =} \StringTok{"Age"}\NormalTok{,}
           \DataTypeTok{is_categorical =}\NormalTok{ F)}
\NormalTok{p2 <-}\StringTok{ }\KeywordTok{plot}\NormalTok{(bpd1,}\DataTypeTok{var_names =} \StringTok{"Age"}\NormalTok{,}
           \DataTypeTok{var_labs =} \KeywordTok{list}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"18-30"}\NormalTok{,}\StringTok{"31-50"}\NormalTok{,}\StringTok{"51-65"}\NormalTok{,}\StringTok{"65+"}\NormalTok{)),}
           \DataTypeTok{is_categorical =}\NormalTok{ T)}
\KeywordTok{grid.arrange}\NormalTok{(p1,p2,}\DataTypeTok{ncol =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{BARP_files/figure-latex/VigFig5-bpd1plot-1} \end{center}

For an interaction analysis of two variables, there may be one of three
different plots produced.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p1 <-}\StringTok{ }\KeywordTok{plot}\NormalTok{(bpd,}
     \DataTypeTok{var_names =} \KeywordTok{c}\NormalTok{(}\StringTok{"Age"}\NormalTok{,}\StringTok{"Education"}\NormalTok{),}
     \DataTypeTok{var_labs =} \KeywordTok{list}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"18-30"}\NormalTok{,}\StringTok{"31-50"}\NormalTok{,}\StringTok{"51-65"}\NormalTok{,}\StringTok{"65+"}\NormalTok{),}
                     \KeywordTok{c}\NormalTok{(}\StringTok{"LTHS"}\NormalTok{,}\StringTok{"HS"}\NormalTok{,}\StringTok{"Some Coll"}\NormalTok{,}\StringTok{"Coll+"}\NormalTok{)),}
     \DataTypeTok{is_categorical =} \KeywordTok{c}\NormalTok{(T,T))}
\NormalTok{p2 <-}\StringTok{ }\KeywordTok{plot}\NormalTok{(bpd,}
     \DataTypeTok{var_names =} \KeywordTok{c}\NormalTok{(}\StringTok{"Age"}\NormalTok{,}\StringTok{"Education"}\NormalTok{),}
     \DataTypeTok{var_labs =} \KeywordTok{list}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"18-30"}\NormalTok{,}\StringTok{"31-50"}\NormalTok{,}\StringTok{"51-65"}\NormalTok{,}\StringTok{"65+"}\NormalTok{),}
                     \KeywordTok{c}\NormalTok{(}\StringTok{"LTHS"}\NormalTok{,}\StringTok{"HS"}\NormalTok{,}\StringTok{"Some Coll"}\NormalTok{,}\StringTok{"Coll+"}\NormalTok{)),}
     \DataTypeTok{is_categorical =} \KeywordTok{c}\NormalTok{(F,T))}
\KeywordTok{grid.arrange}\NormalTok{(p1,p2,}\DataTypeTok{ncol =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{BARP_files/figure-latex/VigFig6-bpd2plot-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(bpd,}
     \DataTypeTok{var_names =} \KeywordTok{c}\NormalTok{(}\StringTok{"Age"}\NormalTok{,}\StringTok{"Education"}\NormalTok{),}
     \DataTypeTok{var_labs =} \KeywordTok{list}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"18-30"}\NormalTok{,}\StringTok{"31-50"}\NormalTok{,}\StringTok{"51-65"}\NormalTok{,}\StringTok{"65+"}\NormalTok{),}
                     \KeywordTok{c}\NormalTok{(}\StringTok{"LTHS"}\NormalTok{,}\StringTok{"HS"}\NormalTok{,}\StringTok{"Some Coll"}\NormalTok{,}\StringTok{"Coll+"}\NormalTok{)),}
     \DataTypeTok{is_categorical =} \KeywordTok{c}\NormalTok{(F,F))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{BARP_files/figure-latex/VigFig7-bpd22plot-1} \end{center}

Finally, for a three-way interaction, the plot will be a grid of
heatmaps, regardless of variable type. The third variable will always be
the one used to organize the grid while the first and second variables
will be the x- and y-axes respectively. Users should limit the number of
levels in the \texttt{barp\_partial\_dependence} function for visual
clarity.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bpd3 <-}\StringTok{ }\KeywordTok{barp_partial_dependence}\NormalTok{(}\DataTypeTok{barp.obj =}\NormalTok{ barp.obj,}
                               \DataTypeTok{vars =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{age =} \DecValTok{1}\OperatorTok{:}\DecValTok{4}\NormalTok{,}\DataTypeTok{educ =} \DecValTok{1}\OperatorTok{:}\DecValTok{4}\NormalTok{,}
                                           \DataTypeTok{state =} \KeywordTok{c}\NormalTok{(}\StringTok{"VT"}\NormalTok{,}\StringTok{"NH"}\NormalTok{,}\StringTok{"ME"}\NormalTok{,}
                                                     \StringTok{"OK"}\NormalTok{,}\StringTok{"NE"}\NormalTok{,}\StringTok{"TX"}\NormalTok{,}
                                                     \StringTok{"CA"}\NormalTok{,}\StringTok{"WA"}\NormalTok{,}\StringTok{"OR"}\NormalTok{)),}
                               \DataTypeTok{prop_data =}\NormalTok{ .}\DecValTok{2}\NormalTok{,}
                               \DataTypeTok{setSeed =} \DecValTok{1021}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(bpd3,}
     \DataTypeTok{var_names =} \KeywordTok{c}\NormalTok{(}\StringTok{"Age"}\NormalTok{,}\StringTok{"Educ"}\NormalTok{,}\StringTok{"Region"}\NormalTok{),}
     \DataTypeTok{var_labs =} \KeywordTok{list}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"18-30"}\NormalTok{,}\StringTok{"31-50"}\NormalTok{,}\StringTok{"51-65"}\NormalTok{,}\StringTok{"65+"}\NormalTok{),}
                     \KeywordTok{c}\NormalTok{(}\StringTok{"LTHS"}\NormalTok{,}\StringTok{"HS"}\NormalTok{,}\StringTok{"Some Coll"}\NormalTok{,}\StringTok{"Coll + "}\NormalTok{),}
                     \KeywordTok{c}\NormalTok{(}\StringTok{"VT"}\NormalTok{,}\StringTok{"NH"}\NormalTok{,}\StringTok{"ME"}\NormalTok{,}
                       \StringTok{"OK"}\NormalTok{,}\StringTok{"NE"}\NormalTok{,}\StringTok{"TX"}\NormalTok{,}
                       \StringTok{"CA"}\NormalTok{,}\StringTok{"WA"}\NormalTok{,}\StringTok{"OR"}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{BARP_files/figure-latex/VigFig8-bpd3plot-1} \end{center}

\subsection{\texorpdfstring{3.0 Covariate importance using
\texttt{barp}}{3.0 Covariate importance using barp}}\label{covariate-importance-using-barp}

The partial dependence analysis informs the user of different
covariates' relationships to the opinion of interest. Instead, however,
researchers may be interested in which covariates matter most to the
BART model. One method of assessing covariate importance is through
examination of how often a covariate is used, either in a tree or as a
splitting rule.

As BART proceeds, it attempts to divide the data to most cleanly
separate observations along the outcome variable. For example, the
fastest way to separate subjects who support gay marriage from those who
oppose it is likely to be to divide the data into two groups -- those
under 50 years of age and those over. This splitting rule may then be
applied to educational attainment and then to gender. Alternatively,
counting the number of times a variable appears in the trees across
posterior samples yields a similar measure. \textbf{BARP's}
\texttt{barp\_prognostic\_covs} function defaults to the splitting rule
(through the
\texttt{type\ =\ \textquotesingle{}splits\textquotesingle{}} parameter).

Over the course of post-burn-in Markov Chain Monte Carlo (MCMC)
iterations and over the branches of a decision tree, a variable may be
chosen as a splitting rule or included in a tree a certain number of
times. The Variable Inclusion Proportion (VIP) of a given covariate is
the share of total splitting rules (or total trees) in which the
covariate is chosen. This proportion is a measure of covariate
importance in the model. For more information, please refer to Bleich et
al. (2014).

\subsubsection{3.1 Average variable inclusion
proportions}\label{average-variable-inclusion-proportions}

To assess the relative covariate importance, \textbf{BARP} includes a
\texttt{barp\_prognostic\_covs} function. This function will return the
observed VIPs for all covariates averaged over a number of runs set by
the user through the \texttt{num\_reps} parameter. The user can also set
the number of trees through the \texttt{num\_trees} parameter which may
differ from the number of trees used in the original \texttt{barp}
command. If the user's goal is predictive accuracy, more trees allow for
more flexibility. When evaluating covariate importance, however,
limiting the number of trees can improve estimation because each
covariate must compete with all others to be included (Chipman, George,
and McCulloch 2010). If not specified by the user, \texttt{num\_trees}
defaults to 20.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{barpcov <-}\StringTok{ }\KeywordTok{barp_prognostic_covs}\NormalTok{(barp.obj,}
                                \DataTypeTok{perm_test =}\NormalTok{ F,}
                                \DataTypeTok{interactions =}\NormalTok{ F,}
                                \DataTypeTok{num_reps =} \DecValTok{30}\NormalTok{,}
                                \DataTypeTok{num_trees =} \DecValTok{20}\NormalTok{,}
                                \DataTypeTok{type =} \StringTok{"splits"}\NormalTok{,}
                                \DataTypeTok{setSeed =} \DecValTok{1021}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{round}\NormalTok{(barpcov}\OperatorTok{$}\NormalTok{covariate_importance }\OperatorTok{%>%}\StringTok{ }\KeywordTok{head}\NormalTok{(),}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        age  educ pvote religcon   gXr region state
## [1,] 0.204 0.129 0.126    0.132 0.189  0.126 0.094
## [2,] 0.196 0.137 0.126    0.150 0.175  0.118 0.098
## [3,] 0.215 0.133 0.106    0.134 0.192  0.098 0.123
## [4,] 0.199 0.138 0.137    0.132 0.163  0.144 0.086
## [5,] 0.203 0.140 0.141    0.143 0.166  0.117 0.090
## [6,] 0.199 0.161 0.115    0.144 0.168  0.098 0.115
\end{verbatim}

The \texttt{barp\_prognostic\_covs} function returns an object of class
\texttt{barpcov} which, if run without a permutation test, contains a
single matrix with the number of rows equal to the \texttt{num\_reps}
parameter and the number of columns equal to the number of variables.
Plotting this object will produce a horizontal bar chart ordered by
variable importance as measured by VIPs. An optional parameter
\texttt{var\_names} allows the user to replace the default variable
names with more descriptive labels.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(barpcov)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{BARP_files/figure-latex/VigFig9-barpcovplot1-1} \end{center}

\subsubsection{3.2 Permutation tests}\label{permutation-tests}

Although the average of the VIPs for all covariates can give the user an
idea of which covariates are most important, it does not allow for
statistical inference. By randomly permuting \(y\) a permutation test
breaks the relationship between all covariates and the outcome variable.
The newly permuted VIPs represent a null distribution to compare with
the observed VIPs. The user can estimate each variable's statistical
significance by setting \texttt{perm\_test\ =\ TRUE} and defining the
number of permutation simulations to run though the
\texttt{num\_permute} parameter.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{barpcov_perm <-}\StringTok{ }\KeywordTok{barp_prognostic_covs}\NormalTok{(barp.obj,}
                                \DataTypeTok{perm_test =}\NormalTok{ T,}
                                \DataTypeTok{num_permute =} \DecValTok{30}\NormalTok{,}
                                \DataTypeTok{interactions =}\NormalTok{ F,}
                                \DataTypeTok{num_reps =} \DecValTok{30}\NormalTok{,}
                                \DataTypeTok{num_trees =} \DecValTok{20}\NormalTok{,}
                                \DataTypeTok{type =} \StringTok{"splits"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{round}\NormalTok{(barpcov_perm}\OperatorTok{$}\NormalTok{permutation_test }\OperatorTok{%>%}\StringTok{ }\KeywordTok{head}\NormalTok{(),}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        age  educ pvote religcon   gXr region state
## [1,] 0.149 0.153 0.138    0.124 0.140  0.135 0.162
## [2,] 0.134 0.153 0.148    0.133 0.143  0.121 0.168
## [3,] 0.133 0.172 0.132    0.137 0.128  0.122 0.177
## [4,] 0.164 0.119 0.120    0.123 0.165  0.128 0.181
## [5,] 0.138 0.131 0.121    0.114 0.193  0.127 0.175
## [6,] 0.146 0.146 0.101    0.180 0.173  0.105 0.148
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{round}\NormalTok{(barpcov_perm}\OperatorTok{$}\NormalTok{p_vals[}\KeywordTok{order}\NormalTok{(barpcov_perm}\OperatorTok{$}\NormalTok{p_vals)],}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      age      gXr religcon    pvote     educ   region    state 
##    0.020    0.030    0.149    0.653    0.693    0.772    1.000
\end{verbatim}

The \texttt{barpcov}-class object now includes a matrix summarizing the
permutation test results and a vector of p-values capturing the
proportion of a variable's permutation test VIPs that fall below the
average observed VIP. The plot command now colors the results by
significance at a user-specified level through \texttt{sig\_level}
(defaults to 0.05), and overlays the VIP value at this level as a
vertical black line.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(barpcov_perm,}
     \DataTypeTok{sig_level =} \FloatTok{0.10}\NormalTok{,}\DataTypeTok{topn =} \DecValTok{20}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{BARP_files/figure-latex/VigFig10-barpcovplot2-1} \end{center}

Alternatively, and as with all \textbf{BARP} outputs, the user may
customize her own visualization using the raw data. In this example, I
plot the histogram of the permutation results for each variable and
overlay the average VIPs as vertical lines.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{require}\NormalTok{(tidyr)}
\NormalTok{toplot <-}\StringTok{ }\KeywordTok{gather}\NormalTok{(}\KeywordTok{as_data_frame}\NormalTok{(barpcov_perm}\OperatorTok{$}\NormalTok{permutation_test),variable,perm)}
\NormalTok{pvals <-}\StringTok{ }\KeywordTok{data_frame}\NormalTok{(}\DataTypeTok{variable =} \KeywordTok{names}\NormalTok{(barpcov_perm}\OperatorTok{$}\NormalTok{p_vals),}\DataTypeTok{pvals =}\NormalTok{ barpcov_perm}\OperatorTok{$}\NormalTok{p_vals)}
\NormalTok{pvals <-}\StringTok{ }\NormalTok{pvals[}\KeywordTok{order}\NormalTok{(pvals}\OperatorTok{$}\NormalTok{pvals),]}
\NormalTok{pvals <-}\StringTok{ }\NormalTok{pvals[}\DecValTok{1}\OperatorTok{:}\KeywordTok{min}\NormalTok{(}\DecValTok{12}\NormalTok{,}\KeywordTok{nrow}\NormalTok{(pvals)),]}
\NormalTok{avgVIPs <-}\StringTok{ }\KeywordTok{apply}\NormalTok{(barpcov_perm}\OperatorTok{$}\NormalTok{covariate_importance,}\DecValTok{2}\NormalTok{,mean)}
\NormalTok{avgVIPs <-}\StringTok{ }\KeywordTok{data_frame}\NormalTok{(}\DataTypeTok{variable =} \KeywordTok{names}\NormalTok{(avgVIPs),}\DataTypeTok{means =}\NormalTok{ avgVIPs)}
\NormalTok{toplot <-}\StringTok{ }\NormalTok{pvals }\OperatorTok{%>%}\StringTok{ }\KeywordTok{left_join}\NormalTok{(toplot) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{left_join}\NormalTok{(avgVIPs)}
\NormalTok{ordered <-}\StringTok{ }\NormalTok{pvals}\OperatorTok{$}\NormalTok{variable}
\NormalTok{toplot <-}\StringTok{ }\NormalTok{toplot }\OperatorTok{%>%}\StringTok{ }\KeywordTok{arrange}\NormalTok{(}\KeywordTok{match}\NormalTok{(variable,ordered))}
\NormalTok{toplot}\OperatorTok{$}\NormalTok{variable <-}\StringTok{ }\KeywordTok{paste0}\NormalTok{(toplot}\OperatorTok{$}\NormalTok{variable,}\StringTok{" ("}\NormalTok{,}\KeywordTok{round}\NormalTok{(toplot}\OperatorTok{$}\NormalTok{pvals,}\DecValTok{2}\NormalTok{),}\StringTok{")"}\NormalTok{)}
\KeywordTok{ggplot}\NormalTok{(toplot, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{perm))}\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_vline}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{xintercept =}\NormalTok{ means), }\DataTypeTok{colour=}\StringTok{"black"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{binwidth=}\FloatTok{0.01}\NormalTok{,}\DataTypeTok{colour =} \StringTok{"white"}\NormalTok{,}\DataTypeTok{fill =} \KeywordTok{rgb}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,.}\DecValTok{3}\NormalTok{)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\NormalTok{variable) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{theme_classic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{BARP_files/figure-latex/VigFig11-barpcovplot3-1} \end{center}

\subsubsection{3.3 Interactions}\label{interactions}

These methods can also be applied to interaction terms.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{barpcov_int <-}\StringTok{ }\KeywordTok{barp_prognostic_covs}\NormalTok{(barp.obj,}
                                \DataTypeTok{perm_test =}\NormalTok{ T,}
                                \DataTypeTok{num_permute =} \DecValTok{30}\NormalTok{,}
                                \DataTypeTok{interactions =}\NormalTok{ T,}
                                \DataTypeTok{num_reps =} \DecValTok{30}\NormalTok{,}
                                \DataTypeTok{num_trees =} \DecValTok{20}\NormalTok{,}
                                \DataTypeTok{type =} \StringTok{"splits"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(barpcov_int,}
     \DataTypeTok{topn =} \DecValTok{25}\NormalTok{,}
     \DataTypeTok{sig_level =} \FloatTok{0.10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{BARP_files/figure-latex/VigFig12-barpcointplot-1} \end{center}

\subsubsection{3.4 Missing Data}\label{missing-data}

The goal of extrapolating representative data from non-representative
surveys is fundamentally a missing data problem where the more sparsely
populated bins constitute the missing data. However, unlike well-known
imputation methods such as \textbf{Amelia} (see Honaker et al. (2011)
for details) which attempt to recover missing data at the unit of the
original data, MRP-style methods predict opinions at the level of
grouped bins of individuals where the bins are defined by observable
covariates.

Nevertheless, there may be situations, particularly in panel data, where
observations are missing at the individual respondent level in a survey.
\textbf{BARP} allows users to implement a variety of imputation methods
via \texttt{use\_missing\_data}, including using the simple average of
the vector of observations
(\texttt{replace\_missing\_data\_with\_x\_j\_bar}), using a linear model
(\texttt{impute\_missingness\_with\_x\_j\_bar\_for\_lm}), or to treat
the missing data as covariates
(\texttt{use\_missing\_data\_dummies\_as\_covars}). A future update of
the \textbf{BARP} package will add in functionality for the random
forest imputation method
(\texttt{impute\_missingness\_with\_rf\_impute}). See Kapelner and
Bleich (2015) for more details on how Bayesian Additive Regression Trees
treat missing data.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{svy}\OperatorTok{$}\NormalTok{age[}\KeywordTok{sample}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\KeywordTok{nrow}\NormalTok{(svy),}\KeywordTok{nrow}\NormalTok{(svy)}\OperatorTok{*}\NormalTok{.}\DecValTok{01}\NormalTok{,}\DataTypeTok{replace =}\NormalTok{ F)] <-}\StringTok{ }\OtherTok{NA}
\NormalTok{svy}\OperatorTok{$}\NormalTok{educ[}\KeywordTok{sample}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\KeywordTok{nrow}\NormalTok{(svy),}\KeywordTok{nrow}\NormalTok{(svy)}\OperatorTok{*}\NormalTok{.}\DecValTok{01}\NormalTok{,}\DataTypeTok{replace =}\NormalTok{ F)] <-}\StringTok{ }\OtherTok{NA}

\NormalTok{barp.covs <-}\StringTok{ }\KeywordTok{barp}\NormalTok{(}\DataTypeTok{y =} \StringTok{"supp_gaymar"}\NormalTok{,}
                 \DataTypeTok{x =} \KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{,}\StringTok{"educ"}\NormalTok{,}\StringTok{"gXr"}\NormalTok{,}
                       \StringTok{"pvote"}\NormalTok{,}\StringTok{"religcon"}\NormalTok{,}
                       \StringTok{"state"}\NormalTok{,}\StringTok{"region"}\NormalTok{),}
                 \DataTypeTok{dat =}\NormalTok{ svy,}\DataTypeTok{census =}\NormalTok{ census06,}
                 \DataTypeTok{geo.unit =} \StringTok{"state"}\NormalTok{,}
                 \DataTypeTok{proportion =} \StringTok{"n"}\NormalTok{,}
                 \DataTypeTok{use_missing_data =} \OtherTok{TRUE}\NormalTok{,}
                 \DataTypeTok{use_missing_data_dummies_as_covars =} \OtherTok{TRUE}\NormalTok{,}
                 \DataTypeTok{setSeed =} \DecValTok{1021}\NormalTok{)}

\NormalTok{barp.xjbar <-}\StringTok{ }\KeywordTok{barp}\NormalTok{(}\DataTypeTok{y =} \StringTok{"supp_gaymar"}\NormalTok{,}
                 \DataTypeTok{x =} \KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{,}\StringTok{"educ"}\NormalTok{,}\StringTok{"gXr"}\NormalTok{,}
                       \StringTok{"pvote"}\NormalTok{,}\StringTok{"religcon"}\NormalTok{,}
                       \StringTok{"state"}\NormalTok{,}\StringTok{"region"}\NormalTok{),}
                 \DataTypeTok{dat =}\NormalTok{ svy,}\DataTypeTok{census =}\NormalTok{ census06,}
                 \DataTypeTok{geo.unit =} \StringTok{"state"}\NormalTok{,}
                 \DataTypeTok{proportion =} \StringTok{"n"}\NormalTok{,}
                 \DataTypeTok{use_missing_data =} \OtherTok{TRUE}\NormalTok{,}
                 \DataTypeTok{replace_missing_data_with_x_j_bar =} \OtherTok{TRUE}\NormalTok{,}
                 \DataTypeTok{setSeed =} \DecValTok{1021}\NormalTok{)}

\NormalTok{barp.xjlm <-}\StringTok{ }\KeywordTok{barp}\NormalTok{(}\DataTypeTok{y =} \StringTok{"supp_gaymar"}\NormalTok{,}
                 \DataTypeTok{x =} \KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{,}\StringTok{"educ"}\NormalTok{,}\StringTok{"gXr"}\NormalTok{,}
                       \StringTok{"pvote"}\NormalTok{,}\StringTok{"religcon"}\NormalTok{,}
                       \StringTok{"state"}\NormalTok{,}\StringTok{"region"}\NormalTok{),}
                 \DataTypeTok{dat =}\NormalTok{ svy,}\DataTypeTok{census =}\NormalTok{ census06,}
                 \DataTypeTok{geo.unit =} \StringTok{"state"}\NormalTok{,}
                 \DataTypeTok{proportion =} \StringTok{"n"}\NormalTok{,}
                 \DataTypeTok{use_missing_data =} \OtherTok{TRUE}\NormalTok{,}
                 \DataTypeTok{impute_missingness_with_x_j_bar_for_lm =} \OtherTok{TRUE}\NormalTok{,}
                 \DataTypeTok{setSeed =} \DecValTok{1021}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cor.mat <-}\StringTok{ }\KeywordTok{cor}\NormalTok{(}\KeywordTok{cbind}\NormalTok{(barp.obj}\OperatorTok{$}\NormalTok{pred.opn}\OperatorTok{$}\NormalTok{SL.bartMachine_1_All,}
\NormalTok{          barp.xjbar}\OperatorTok{$}\NormalTok{pred.opn}\OperatorTok{$}\NormalTok{SL.bartMachine_1_All,}
\NormalTok{          barp.xjlm}\OperatorTok{$}\NormalTok{pred.opn}\OperatorTok{$}\NormalTok{SL.bartMachine_1_All,}
\NormalTok{          barp.covs}\OperatorTok{$}\NormalTok{pred.opn}\OperatorTok{$}\NormalTok{SL.bartMachine_1_All))}
\KeywordTok{colnames}\NormalTok{(cor.mat) <-}\StringTok{ }\KeywordTok{rownames}\NormalTok{(cor.mat) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"No Missing"}\NormalTok{,}
                                            \StringTok{"Impute Xj Bar"}\NormalTok{,}
                                            \StringTok{"Impute Xj LM"}\NormalTok{,}
                                            \StringTok{"Missing as Covs"}\NormalTok{)}
\KeywordTok{round}\NormalTok{(cor.mat,}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                 No Missing Impute Xj Bar Impute Xj LM Missing as Covs
## No Missing           1.000         0.987        0.993           0.989
## Impute Xj Bar        0.987         1.000        0.993           0.991
## Impute Xj LM         0.993         0.993        1.000           0.993
## Missing as Covs      0.989         0.991        0.993           1.000
\end{verbatim}

\subsection{4.0 Alternative Regularization
Methods}\label{alternative-regularization-methods}

The updated \textbf{BARP} package allows users to replace or add
additional regularization algorithms via the \texttt{method} parameter.
These algorithms can be one of the 43 methods included in the
\texttt{SuperLearner} package (Polley and Van der Laan 2015) although
users must ensure that the associated dependencies are installed. A
detailed introduction to this package can be found
\href{https://cran.r-project.org/web/packages/SuperLearner/vignettes/Guide-to-SuperLearner.html}{here}.

The easiest implementation of these alternative algorithms is to include
one or more as a character vector. In this case, I use the vanilla
implementation of \texttt{SL.glmnet}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{data}\NormalTok{(}\StringTok{"gaymar"}\NormalTok{)}
\NormalTok{census06 <-}\StringTok{ }\NormalTok{census06 }\OperatorTok{%>%}\StringTok{ }\KeywordTok{merge}\NormalTok{(svy }\OperatorTok{%>%}\StringTok{ }\NormalTok{dplyr}\OperatorTok{::}\KeywordTok{select}\NormalTok{(state,stateid) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{distinct}\NormalTok{())}

\NormalTok{barp.objSL <-}\StringTok{ }\KeywordTok{barp}\NormalTok{(}\DataTypeTok{y =} \StringTok{"supp_gaymar"}\NormalTok{,}
                 \DataTypeTok{x =} \KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{,}\StringTok{"educ"}\NormalTok{,}\StringTok{"gXr"}\NormalTok{,}
                       \StringTok{"pvote"}\NormalTok{,}\StringTok{"religcon"}\NormalTok{,}
                       \StringTok{"state"}\NormalTok{,}\StringTok{"region"}\NormalTok{),}
                 \DataTypeTok{dat =}\NormalTok{ svy,}\DataTypeTok{census =}\NormalTok{ census06,}
                 \DataTypeTok{algorithm =} \KeywordTok{c}\NormalTok{(}\StringTok{"SL.glmnet"}\NormalTok{),}
                 \DataTypeTok{geo.unit =} \StringTok{"state"}\NormalTok{,}
                 \DataTypeTok{proportion =} \StringTok{"n"}\NormalTok{,}
                 \DataTypeTok{setSeed =} \DecValTok{1021}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{barp.objSL}\OperatorTok{$}\NormalTok{pred.opn }\OperatorTok{%>%}\StringTok{ }\KeywordTok{head}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    state SL.glmnet_All opn.lb opn.ub
## AL    AL     0.1661456     NA     NA
## AR    AR     0.1345653     NA     NA
## AZ    AZ     0.2977428     NA     NA
## CA    CA     0.3635293     NA     NA
## CO    CO     0.3541205     NA     NA
## CT    CT     0.3854912     NA     NA
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(barp.objSL,}\DataTypeTok{algorithm =} \StringTok{"SL.glmnet"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{BARP_files/figure-latex/VigFig13-slpreds-1} \end{center}

Unlike with \texttt{barp} objects, other algorithms do not provide
uncertainty estimates without turning on bootstraps with
\texttt{BSSD\ =\ TRUE}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{barp.objSLBS <-}\StringTok{ }\KeywordTok{barp}\NormalTok{(}\DataTypeTok{y =} \StringTok{"supp_gaymar"}\NormalTok{,}
                 \DataTypeTok{x =} \KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{,}\StringTok{"educ"}\NormalTok{,}\StringTok{"gXr"}\NormalTok{,}
                       \StringTok{"pvote"}\NormalTok{,}\StringTok{"religcon"}\NormalTok{,}
                       \StringTok{"state"}\NormalTok{,}\StringTok{"region"}\NormalTok{),}
                 \DataTypeTok{dat =}\NormalTok{ svy,}\DataTypeTok{census =}\NormalTok{ census06,}
                 \DataTypeTok{algorithm =} \KeywordTok{c}\NormalTok{(}\StringTok{"SL.glmnet"}\NormalTok{),}
                 \DataTypeTok{geo.unit =} \StringTok{"state"}\NormalTok{,}
                 \DataTypeTok{proportion =} \StringTok{"n"}\NormalTok{,}
                 \DataTypeTok{BSSD =} \OtherTok{TRUE}\NormalTok{,}
                 \DataTypeTok{nsims =} \DecValTok{50}\NormalTok{,}
                 \DataTypeTok{setSeed =} \DecValTok{1021}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{barp.objSLBS}\OperatorTok{$}\NormalTok{pred.opn }\OperatorTok{%>%}\StringTok{ }\KeywordTok{head}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   state  pred.opn     opn.lb    opn.ub
## 1    AL 0.1860024 0.13558079 0.2579651
## 2    AR 0.1201974 0.05798779 0.1782284
## 3    AZ 0.3214124 0.25244014 0.3980291
## 4    CA 0.3672889 0.34826682 0.3950198
## 5    CO 0.3631236 0.30516150 0.4702434
## 6    CT 0.4153072 0.35595841 0.5055253
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(barp.objSLBS)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{BARP_files/figure-latex/VigFig14-slBS-1} \end{center}

These algorithms can be customized as described in the
\texttt{SuperLearner} documentation. For example, if we wanted to run a
random forest with 150 trees, we would do the following:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rf_new <-}\StringTok{ }\KeywordTok{create.Learner}\NormalTok{(}\StringTok{"SL.randomForest"}\NormalTok{,}\DataTypeTok{params =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{ntree =} \DecValTok{150}\NormalTok{))}
\NormalTok{barp.objRF <-}\StringTok{ }\KeywordTok{barp}\NormalTok{(}\DataTypeTok{y =} \StringTok{"supp_gaymar"}\NormalTok{,}
                 \DataTypeTok{x =} \KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{,}\StringTok{"educ"}\NormalTok{,}\StringTok{"gXr"}\NormalTok{,}
                       \StringTok{"pvote"}\NormalTok{,}\StringTok{"religcon"}\NormalTok{,}
                       \StringTok{"state"}\NormalTok{,}\StringTok{"region"}\NormalTok{),}
                 \DataTypeTok{dat =}\NormalTok{ svy,}\DataTypeTok{census =}\NormalTok{ census06,}
                 \DataTypeTok{algorithm =} \KeywordTok{c}\NormalTok{(rf_new}\OperatorTok{$}\NormalTok{names),}
                 \DataTypeTok{geo.unit =} \StringTok{"state"}\NormalTok{,}
                 \DataTypeTok{proportion =} \StringTok{"n"}\NormalTok{,}
                 \DataTypeTok{setSeed =} \DecValTok{1021}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{barp.objRF}\OperatorTok{$}\NormalTok{pred.opn }\OperatorTok{%>%}\StringTok{ }\KeywordTok{head}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    state SL.randomForest_1_All opn.lb opn.ub
## AL    AL            0.02913993     NA     NA
## AR    AR            0.01521739     NA     NA
## AZ    AZ            0.14342199     NA     NA
## CA    CA            0.14478368     NA     NA
## CO    CO            0.25880952     NA     NA
## CT    CT            0.33599271     NA     NA
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(barp.objRF)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{BARP_files/figure-latex/VigFig15-rfpreds-1} \end{center}

Finally, we can test multiple algorithms at once and examine which
perform the best via cross validation by feeding in a vector of
algorithm names to the \texttt{algorithm} parameter.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{barp.objEns <-}\StringTok{ }\KeywordTok{barp}\NormalTok{(}\DataTypeTok{y =} \StringTok{"supp_gaymar"}\NormalTok{,}
                 \DataTypeTok{x =} \KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{,}\StringTok{"educ"}\NormalTok{,}\StringTok{"gXr"}\NormalTok{,}
                       \StringTok{"pvote"}\NormalTok{,}\StringTok{"religcon"}\NormalTok{,}
                       \StringTok{"state"}\NormalTok{,}\StringTok{"region"}\NormalTok{),}
                 \DataTypeTok{dat =}\NormalTok{ svy,}\DataTypeTok{census =}\NormalTok{ census06,}
                 \DataTypeTok{algorithm =} \KeywordTok{c}\NormalTok{(rf_new}\OperatorTok{$}\NormalTok{names,}\StringTok{"SL.glmnet"}\NormalTok{,}\StringTok{"SL.randomForest"}\NormalTok{),}
                 \DataTypeTok{geo.unit =} \StringTok{"state"}\NormalTok{,}
                 \DataTypeTok{proportion =} \StringTok{"n"}\NormalTok{,}
                 \DataTypeTok{setSeed =} \DecValTok{1021}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{barp.objEns}\OperatorTok{$}\NormalTok{pred.opn }\OperatorTok{%>%}\StringTok{ }\KeywordTok{head}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    state SL.randomForest_1_All SL.glmnet_All SL.randomForest_All
## AL    AL            0.03346351     0.1661456          0.02982427
## AR    AR            0.01981159     0.1345653          0.01366304
## AZ    AZ            0.12843085     0.2977428          0.13021941
## CA    CA            0.12583631     0.3635293          0.13147678
## CO    CO            0.25814103     0.3541205          0.24294918
## CT    CT            0.32847602     0.3854912          0.35322040
##           ens     opn.lb    opn.ub
## AL 0.10949208 0.02681255 0.1637349
## AR 0.08493234 0.01357357 0.1308434
## AZ 0.22680901 0.12184227 0.2934351
## CA 0.26460884 0.12359648 0.3572818
## CO 0.31048271 0.23437961 0.3644853
## CT 0.36670956 0.32045860 0.3985555
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(barp.objEns)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{BARP_files/figure-latex/VigFig16-ensPreds-1} \end{center}

As illustrated, the \texttt{SL.randomForest} algorithm returns very
similar predictions when using the default number of trees (1,000)
versus 150. We can further examine how these algorithms perform by
looking at their cross-validated risk via the \texttt{risk} object in
the output. The first column returns the performance metric (typically
AUC for classification, NNLS for regression,although these can be
adjusted by the user) and the second provides the weight associated with
this algorithm in estimating the ensemble predictions.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{barp.objEns}\OperatorTok{$}\NormalTok{risk}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                             AUC      coef
## SL.randomForest_1_All 0.3560406 0.2097273
## SL.glmnet_All         0.3309479 0.5788130
## SL.randomForest_All   0.3529118 0.2114597
\end{verbatim}

Some of these algorithms require bespoke packages which will need to be
installed before running \texttt{barp}. In addition, others may only
work for classification or regression and will give an error if applied
to the incorrect data type.

\subsection{5.0 Conclusion}\label{conclusion}

This vignette has introduced and demonstrated the features of the
\textbf{R} package \textbf{BARP}. The purpose of this package is to
improve on the estimation of opinion at narrower levels of geography
than originally represented in a survey. The package includes several
helper functions designed to facilitate exploration of the model, both
in terms of performance and in terms of covariates. I invite comments on
bugs, corrections, improvements, and any other suggestions.

\subsection*{References}\label{references}
\addcontentsline{toc}{subsection}{References}

\hypertarget{refs}{}
\hypertarget{ref-bisbee2019barp}{}
Bisbee, James. 2019. ``BARP: Improving Mister P Using Bayesian Additive
Regression Trees.'' \emph{Working Paper}.
\url{jamesbisbee.com/research}.

\hypertarget{ref-bleich2014variable}{}
Bleich, Justin, Adam Kapelner, Edward I George, and Shane T Jensen.
2014. ``Variable Selection for Bart: An Application to Gene
Regulation.'' \emph{The Annals of Applied Statistics}. JSTOR, 1750--81.

\hypertarget{ref-buttice_how_2013}{}
Buttice, Matthew K., and Benjamin Highton. 2013. ``How Does Multilevel
Regression and Poststratification Perform with Conventional National
Surveys?'' \emph{Political Analysis} 21 (4): 449--67.

\hypertarget{ref-chipman_bart:_2010}{}
Chipman, Hugh A., Edward I. George, and Robert E. McCulloch. 2010.
``BART: Bayesian Additive Regression Trees.'' \emph{The Annals of
Applied Statistics}, 266--98.

\hypertarget{ref-honaker2011amelia}{}
Honaker, James, Gary King, Matthew Blackwell, and others. 2011. ``Amelia
Ii: A Program for Missing Data.'' \emph{Journal of Statistical Software}
45 (7): 1--47.

\hypertarget{ref-kapelner2013bartmachine}{}
Kapelner, Adam, and Justin Bleich. 2013. ``Bartmachine: A Powerful Tool
for Machine Learning.'' \emph{Stat} 1050: 8.

\hypertarget{ref-kapelner2015prediction}{}
---------. 2015. ``Prediction with Missing Data via Bayesian Additive
Regression Trees.'' \emph{Canadian Journal of Statistics} 43 (2). Wiley
Online Library: 224--39.

\hypertarget{ref-lax_how_2009}{}
Lax, Jeffrey R., and Justin H. Phillips. 2009. ``How Should We Estimate
Public Opinion in the States?'' \emph{American Journal of Political
Science} 53 (1): 107--21.

\hypertarget{ref-polley2015superlearner}{}
Polley, EC, and MJ Van der Laan. 2015. ``SuperLearner: Super Learner
Prediction.(Package Version 2.0-15).'' \emph{Vienna, Austria: R
Foundation for Statistical Computing}.

\hypertarget{ref-warshaw_how_2012}{}
Warshaw, Christopher, and Jonathan Rodden. 2012. ``How Should We Measure
District-Level Public Opinion on Individual Issues?'' \emph{The Journal
of Politics} 74 (01): 203--19.


\end{document}
